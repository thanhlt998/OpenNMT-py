# train.yaml

## Where the samples will be written
#save_data: models/v2/split_rephrase_v1
## Where the vocab(s) will be written
#src_vocab: models/v2/split_rephrase_v1.vocab.src
#tgt_vocab: models/v2/split_rephrase_v1.vocab.tgt
#share_vocab: True
vocab: models/v2/split_rephrase_v1.vocab.pt
src_seq_length: 256
tgt_seq_length: 256
src_seq_length_trunc: 256
tgt_seq_length_trunc: 256
#bert_src: vinai/phobert-base
#bert_tgt: vinai/phobert-base
#shard_size: 100000
#src_vocab_size: 200000
#tgt_vocab_size: 200000
# Prevent overwriting existing files in the folder
overwrite: False

# log
log_file: models/v2/log/viwikisplit_bert.log

# Source
src: data/vi_wikisplit_200k/test_data.complex

# Save model
save_model: models/v2/checkpoints/viwikisplit_bert

# Model options

# Dimensionality
rnn_size: 768
word_vec_size: 768
#feat_vec_size: 2048
transformer_ff: 3072
heads: 12
layers: 12

# Embeddings
position_encoding: True
share_embeddings: True
share_decoder_embeddings: True

# Encoder
encoder_type: bert
enc_bert_type: vinai/phobert-base

# Decoder
decoder_type: bert
dec_bert_type: vinai/phobert-base
bert_decoder_token_type: B

# Layer Sharing
bert_decoder_init_context: True
share_self_attn: True
tie_context_attn: True
share_feed_forward: True
copy_attn: True

